{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a965848-86fd-481b-b348-c56fba38dfcc",
   "metadata": {
    "id": "9a965848-86fd-481b-b348-c56fba38dfcc"
   },
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf8f5dc-0e04-42c3-a27d-7b6873a76522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_4emlohv9aUS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4emlohv9aUS",
    "outputId": "7c709922-ed6e-43cd-c9d2-23c4853973b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 27 10:32:36 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              90W / 400W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbf336",
   "metadata": {
    "id": "78cbf336",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import random\n",
    "from typing import Tuple, List, Union\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Subset, random_split\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from diffusers import DDPMScheduler, DDIMScheduler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8b4d8-a412-46ab-be70-cc24d81911a6",
   "metadata": {
    "id": "c3d8b4d8-a412-46ab-be70-cc24d81911a6"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Data\n",
    "    image_size = 32\n",
    "\n",
    "    # Model\n",
    "    model_channels: int = 128\n",
    "    num_res_blocks: int = 2\n",
    "    attention_resolutions: Tuple[int] = (8, 4)\n",
    "\n",
    "\n",
    "    # Noise Scheduler\n",
    "    num_train_timesteps = 1_000\n",
    "    num_inference_steps = 20\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    beta_schedule = \"squaredcos_cap_v2\"\n",
    "\n",
    "    # Training\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "\n",
    "    # Accelerator\n",
    "    gradient_accumulation_steps = 16\n",
    "    mixed_precision = 'fp16'  # `no` for float32, `fp16` for automatic mixed precision\n",
    "\n",
    "    device = \"cuda\"\n",
    "    random_state = 42\n",
    "\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fedcf",
   "metadata": {
    "id": "a65fedcf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int,\n",
    "                    use_deterministic_algos: bool = False) -> None:\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(use_deterministic_algos)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "seed_everything(config.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774BNDTEK7ZO",
   "metadata": {
    "id": "774BNDTEK7ZO"
   },
   "outputs": [],
   "source": [
    "PATH = \"/home/jovyan/novitskiy/3d-material-diffusion\"\n",
    "DATA = PATH + \"/data/berea_sandstone/\"\n",
    "TRAIN = DATA + \"Berea_2d25um_grayscale_filtered.raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DZME0gB5RPe4",
   "metadata": {
    "id": "DZME0gB5RPe4"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8e449-b628-4bc2-98e5-b5abf7184111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(x):\n",
    "    \"\"\"Given a batch of images x, make a grid and convert to PIL\"\"\"\n",
    "    x = x * 0.5 + 0.5  # Map from (-1, 1) back to (0, 1)\n",
    "    grid = torchvision.utils.make_grid(x)\n",
    "    grid_im = grid.detach().cpu().permute(1, 2, 0).clip(0, 1) * 255\n",
    "    grid_im = Image.fromarray(np.array(grid_im).astype(np.uint8))\n",
    "    return grid_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GlXHcqf0RQ6U",
   "metadata": {
    "id": "GlXHcqf0RQ6U"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MaterialsDataset(Dataset):\n",
    "    def __init__(self, path_to_3d_material: str = \"\", transforms = None, chunk_size: int = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.path_to_3d_material = path_to_3d_material\n",
    "        self.transforms = transforms\n",
    "        self.chunk_size = chunk_size\n",
    "        self.material = torch.from_numpy(\n",
    "            np.fromfile(\n",
    "                self.path_to_3d_material, dtype='int8', sep=\"\"\n",
    "            ).reshape(1000, 1000, 1000)\n",
    "        )\n",
    "        self.material = self._truncate(self.material)\n",
    "        self.chunks = self._get_chunks(self.material, self.chunk_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_chunks(material, chunk_size):\n",
    "        chunks = []\n",
    "\n",
    "        d, h, w = material.shape\n",
    "\n",
    "        for i in range(d // chunk_size):\n",
    "            for j in range(h // chunk_size):\n",
    "                for k in range(h // chunk_size):\n",
    "                    chunks.append(\n",
    "                        material[\n",
    "                            i * chunk_size:(i + 1) * chunk_size,\n",
    "                            j * chunk_size:(j + 1) * chunk_size,\n",
    "                            k * chunk_size:(k + 1) * chunk_size,\n",
    "                        ].unsqueeze(0)\n",
    "                    )\n",
    "\n",
    "        chunks = torch.cat(chunks, dim=0)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    @staticmethod\n",
    "    def _truncate(material, h=1000, w=1000):\n",
    "        return material[:, :h, :w]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        chunk = self.chunks[idx]\n",
    "\n",
    "        if self.transforms:\n",
    "            chunk = self.transforms(chunk)\n",
    "\n",
    "        return chunk.unsqueeze(dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.chunks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vG9x5KSIXp5V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "vG9x5KSIXp5V",
    "outputId": "b2a289f0-5a26-4871-d36a-abfff1bde9fd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.fromfile(TRAIN, dtype='int8', sep=\"\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127b831-6b92-45f9-b8a7-3dbd2e5b62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(1000, 1000, 1000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f224465-4ec3-4a01-97b9-53bc9af3c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(torch.tensor(data)[:16].unsqueeze(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a2b33-e4fe-4dd4-9394-f9256798047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[0][:100, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SV8L5CFRfF_r",
   "metadata": {
    "id": "SV8L5CFRfF_r"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.Lambda(lambda x: x / 255),\n",
    "        transforms.Normalize([0.5], [0.5]),  # Map to (-1, 1)\n",
    "])\n",
    "\n",
    "\n",
    "dataset = MaterialsDataset(\n",
    "    TRAIN,\n",
    "    chunk_size=config.image_size,\n",
    "    transforms=transform,\n",
    ")\n",
    "\n",
    "train_inds,  eval_inds = train_test_split(\n",
    "    [i for i in range(len(dataset))],\n",
    "    test_size=0.1,\n",
    "    random_state=config.random_state\n",
    "    )\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    Subset(dataset, train_inds),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    Subset(dataset, eval_inds),\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UHvY21A9fSYZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHvY21A9fSYZ",
    "outputId": "c14d57a9-e028-42a7-a76c-eae683a17f1a"
   },
   "outputs": [],
   "source": [
    "next(iter(eval_dataloader)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ac654f-8593-43fb-84fd-3f02dc59103e",
   "metadata": {
    "id": "02ac654f-8593-43fb-84fd-3f02dc59103e"
   },
   "source": [
    "### Utils for diffusion processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc29f2-e346-4223-ba88-9a840d6a460f",
   "metadata": {
    "id": "d1cc29f2-e346-4223-ba88-9a840d6a460f"
   },
   "outputs": [],
   "source": [
    "def generate(x, model, noise_scheduler, device: str, num_inference_steps: int = 100):\n",
    "    x, model = x.to(device), model.to(device)\n",
    "    noise_scheduler.set_timesteps(num_inference_steps=num_inference_steps)\n",
    "    bs = x.shape[0]\n",
    "    for i, t in enumerate(noise_scheduler.timesteps):\n",
    "        model_input = noise_scheduler.scale_model_input(x, t)\n",
    "\n",
    "        t_batch = torch.full(\n",
    "            size=(bs,),\n",
    "            fill_value=t.item(),\n",
    "            dtype=torch.long\n",
    "        ).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            noise_pred = model(\n",
    "                model_input,\n",
    "                t_batch\n",
    "            )\n",
    "\n",
    "        x = noise_scheduler.step(noise_pred, t, x).prev_sample\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2d8c1-bc17-4e9d-bf2d-04b93d607494",
   "metadata": {
    "id": "a1c2d8c1-bc17-4e9d-bf2d-04b93d607494"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf08aa4",
   "metadata": {
    "id": "bdf08aa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    accelerator,\n",
    "    noise_scheduler,\n",
    "    loss,\n",
    "    epochs: int,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    eval_dataloader: torch.utils.data.DataLoader,\n",
    "    device: str,\n",
    "):\n",
    "    pbar = range(epochs)\n",
    "    for epoch in pbar:\n",
    "        train_losses = []\n",
    "        eval_losses = []\n",
    "\n",
    "        #-------------------------------------------------------------#\n",
    "        # Train epoch\n",
    "        model.train()\n",
    "        train_losses_per_epoch = []\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            x_1 = batch.to(device)\n",
    "\n",
    "            bs = x_1.shape[0]\n",
    "            noise = torch.rand(x_1.shape).to(x_1.device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.num_train_timesteps, (bs,), device=x_1.device\n",
    "            ).long()\n",
    "\n",
    "            noisy_x_1 = noise_scheduler.add_noise(x_1, noise, timesteps)\n",
    "\n",
    "            with accelerator.accumulate(model):\n",
    "                output = model(\n",
    "                    noisy_x_1,\n",
    "                    timesteps\n",
    "                )\n",
    "\n",
    "                train_loss = loss(noise, output)\n",
    "                accelerator.backward(train_loss)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            train_losses.append(train_loss.item() / bs)\n",
    "\n",
    "        train_dict = {\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"train_loss\": np.mean(train_losses),\n",
    "                     }\n",
    "\n",
    "        #-------------------------------------------------------------#\n",
    "        # Eval epoch\n",
    "        model.eval()\n",
    "        eval_losses_per_epoch = []\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            x_1 = batch.to(device)\n",
    "\n",
    "            bs = x_1.shape[0]\n",
    "            noise = torch.rand(x_1.shape).to(x_1.device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.num_train_timesteps, (bs,), device=x_1.device\n",
    "            ).long()\n",
    "\n",
    "            noisy_x_1 = noise_scheduler.add_noise(x_1, noise, timesteps)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(\n",
    "                    noisy_x_1,\n",
    "                    timesteps\n",
    "                )\n",
    "\n",
    "                eval_loss = loss(noise, output)\n",
    "\n",
    "            eval_losses.append(eval_loss.item() / bs)\n",
    "\n",
    "        eval_dict = {\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"eval_loss\": np.mean(eval_losses),\n",
    "                     }\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(model, f\"checkpoints/baseline_3/{epoch}.pt\",)\n",
    "        \n",
    "        x_gen = generate(\n",
    "            x=torch.randn((1, 1, config.image_size, config.image_size, config.image_size)),\n",
    "            model=model,\n",
    "            noise_scheduler=noise_scheduler,\n",
    "            device=device\n",
    "        ).cpu()[0][0]\n",
    " \n",
    "        \n",
    "        train_dict.update(eval_dict)\n",
    "        train_dict[\"reconstructed\"] = wandb.Image(\n",
    "            show_images(x_gen[:16].unsqueeze(dim=1))\n",
    "        )\n",
    "        wandb.log(\n",
    "            train_dict\n",
    "        )\n",
    "        \n",
    "        print(train_dict, eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "GxalRG0Q5BVV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxalRG0Q5BVV",
    "outputId": "def37bdd-c4c6-4edf-9bda-d2e3b7656994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'improved-diffusion' already exists and is not an empty directory.\n",
      "usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "   or: setup.py --help [cmd1 cmd2 ...]\n",
      "   or: setup.py --help-commands\n",
      "   or: setup.py cmd --help\n",
      "\n",
      "error: no commands supplied\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/improved-diffusion.git\n",
    "!python3 ./improved-diffusion/setup.py\n",
    "sys.path.append(\"./improved-diffusion/improved_diffusion\")\n",
    "sys.path.append(\"./improved-diffusion/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73a39f94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73a39f94",
    "outputId": "292c6d8b-6e53-4d0d-9ffd-597f6826babe",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDIMScheduler {\n",
       "  \"_class_name\": \"DDIMScheduler\",\n",
       "  \"_diffusers_version\": \"0.27.2\",\n",
       "  \"beta_end\": 0.02,\n",
       "  \"beta_schedule\": \"squaredcos_cap_v2\",\n",
       "  \"beta_start\": 0.0001,\n",
       "  \"clip_sample\": true,\n",
       "  \"clip_sample_range\": 1.0,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"epsilon\",\n",
       "  \"rescale_betas_zero_snr\": false,\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"set_alpha_to_one\": true,\n",
       "  \"steps_offset\": 0,\n",
       "  \"thresholding\": false,\n",
       "  \"timestep_spacing\": \"leading\",\n",
       "  \"trained_betas\": null\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from improved_diffusion.unet import UNetModel\n",
    "\n",
    "model = UNetModel(\n",
    "    in_channels=1, # should be equal to num_features (input features)\n",
    "    dims=3, #this states, that we are using 1D U-Net\n",
    "    model_channels=config.model_channels, # inner model features\n",
    "    out_channels=1, # should be equal to num_features (input features)\n",
    "    num_res_blocks=config.num_res_blocks, \n",
    "    attention_resolutions=config.attention_resolutions\n",
    ")\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "total_steps = int(len(train_dataloader) * config.epochs)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                    num_warmup_steps = config.lr_warmup_steps, # Default value in run_glue.py\n",
    "                                    num_training_steps = total_steps)\n",
    "\n",
    "ddim_scheduler = DDIMScheduler(\n",
    "    num_train_timesteps=config.num_train_timesteps,\n",
    "    beta_start=config.beta_start,\n",
    "    beta_end=config.beta_end,\n",
    "    beta_schedule=config.beta_schedule,\n",
    "\n",
    ")\n",
    "ddim_scheduler.set_timesteps(\n",
    "    num_inference_steps=config.num_inference_steps\n",
    ")\n",
    "\n",
    "ddim_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c97eda-27a2-4409-8929-6bb10fd3d852",
   "metadata": {
    "id": "a8c97eda-27a2-4409-8929-6bb10fd3d852"
   },
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n",
    "    train_dataloader, eval_dataloader, model, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ae0180-e0d1-4194-bbf7-2111d49ccd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin 16e2a17c9f21df376f01b89f927dec88e33c2369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23b001a7-6c1c-446a-b5c1-38f468939587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29791"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee4f111a-17fd-4da2-901f-acb528ab6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleffff\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/novitskiy/3d-material-diffusion/wandb/run-20240427_100747-5u02gg20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leffff/Microstructures/runs/5u02gg20' target=\"_blank\">3D Unet Baseline</a></strong> to <a href='https://wandb.ai/leffff/Microstructures' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/leffff/Microstructures' target=\"_blank\">https://wandb.ai/leffff/Microstructures</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/leffff/Microstructures/runs/5u02gg20' target=\"_blank\">https://wandb.ai/leffff/Microstructures/runs/5u02gg20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/leffff/Microstructures/runs/5u02gg20?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ffa1432d040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "model_name = \"3D Unet Baseline\"\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    entity=\"leffff\",\n",
    "    project=\"Microstructures\",\n",
    "    name=model_name,\n",
    "    # track hyperparameters and run metadata\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "633997af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "633997af",
    "outputId": "04b312fb-f4ab-42b5-bbe6-594688d11fc5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 838/838 [18:10<00:00,  1.30s/it]\n",
      "100%|██████████| 94/94 [00:46<00:00,  2.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddim_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, accelerator, noise_scheduler, loss, epochs, train_dataloader, eval_dataloader, device)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     85\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/baseline_3/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[0;32m---> 87\u001b[0m x_gen \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     95\u001b[0m train_dict\u001b[38;5;241m.\u001b[39mupdate(eval_dict)\n\u001b[1;32m     96\u001b[0m train_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconstructed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mImage(\n\u001b[1;32m     97\u001b[0m     show_images(x_gen[:\u001b[38;5;241m16\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     98\u001b[0m )\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(x, model, noise_scheduler, device, num_inference_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(noise_scheduler\u001b[38;5;241m.\u001b[39mtimesteps):\n\u001b[1;32m      6\u001b[0m     model_input \u001b[38;5;241m=\u001b[39m noise_scheduler\u001b[38;5;241m.\u001b[39mscale_model_input(x, t)\n\u001b[0;32m----> 8\u001b[0m     t_batch \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     15\u001b[0m         noise_pred \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     16\u001b[0m             model_input,\n\u001b[1;32m     17\u001b[0m             t_batch\n\u001b[1;32m     18\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    accelerator=accelerator,\n",
    "    noise_scheduler=ddim_scheduler,\n",
    "    loss=F.mse_loss,\n",
    "    epochs=config.epochs,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    device=config.device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda]",
   "language": "python",
   "name": "conda-env-.conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
